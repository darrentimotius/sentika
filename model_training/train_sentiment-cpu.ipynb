{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60c5b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from transformers import BertForSequenceClassification, BertConfig, BertTokenizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef38d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# common functions\n",
    "###\n",
    "LABEL2INDEX = {'positive': 0, 'neutral': 1, 'negative': 2}\n",
    "INDEX2LABEL = {0: 'positive', 1: 'neutral', 2: 'negative'}\n",
    "NUM_LABELS = 3\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "def count_param(module, trainable=False):\n",
    "    if trainable:\n",
    "        return sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "    else:\n",
    "        return sum(p.numel() for p in module.parameters())\n",
    "    \n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def metrics_to_string(metric_dict):\n",
    "    string_list = []\n",
    "    for key, value in metric_dict.items():\n",
    "        string_list.append('{}:{:.2f}'.format(key, value))\n",
    "    return ' '.join(string_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1308fd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "set_seed(26092020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e65f947e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load Tokenizer and Config\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "config = BertConfig.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "config.num_labels = NUM_LABELS\n",
    "\n",
    "# Instantiate model\n",
    "model = BertForSequenceClassification.from_pretrained('indobenchmark/indobert-base-p1', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a359f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    df = pd.read_csv(path, sep='\\t', header=None)\n",
    "    df.columns = ['text', 'sentiment']\n",
    "    df['sentiment'] = df['sentiment'].apply(lambda lab: LABEL2INDEX[lab])\n",
    "    return df\n",
    "\n",
    "def encode_dataset(df, tokenizer, no_special_token=False):\n",
    "    encoded = []\n",
    "    for _, row in df.iterrows():\n",
    "        text = row['text']\n",
    "        sentiment = row['sentiment']\n",
    "        subwords = tokenizer.encode(text, add_special_tokens=not no_special_token)\n",
    "        encoded.append((np.array(subwords), np.array(sentiment), text))\n",
    "    return encoded\n",
    "\n",
    "def collate_fn(batch, max_seq_len=512):\n",
    "    batch_size = len(batch)\n",
    "    max_len = min(max(len(x[0]) for x in batch), max_seq_len)\n",
    "    \n",
    "    subword_batch = np.zeros((batch_size, max_len), dtype=np.int64)\n",
    "    mask_batch = np.zeros((batch_size, max_len), dtype=np.float32)\n",
    "    sentiment_batch = np.zeros((batch_size, 1), dtype=np.int64)\n",
    "    seq_list = []\n",
    "\n",
    "    for i, (subwords, sentiment, raw_seq) in enumerate(batch):\n",
    "        subwords = subwords[:max_len]\n",
    "        subword_batch[i, :len(subwords)] = subwords\n",
    "        mask_batch[i, :len(subwords)] = 1\n",
    "        sentiment_batch[i, 0] = sentiment\n",
    "        seq_list.append(raw_seq)\n",
    "\n",
    "    return (\n",
    "        torch.tensor(subword_batch),\n",
    "        torch.tensor(mask_batch),\n",
    "        torch.tensor(sentiment_batch),\n",
    "        seq_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e15e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = '../data/smsa/train_preprocess.tsv'\n",
    "valid_dataset_path = '../data/smsa/valid_preprocess.tsv'\n",
    "test_dataset_path = '../data/smsa/test_preprocess.tsv'\n",
    "test_labeling_path = '../data/smsa/test_preprocess_masked_label.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c60d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_dataset(train_dataset_path)\n",
    "valid_df = load_dataset(valid_dataset_path)\n",
    "test_df  = load_dataset(test_dataset_path)\n",
    "test_label_df = load_dataset(test_labeling_path)\n",
    "\n",
    "train_encoded = encode_dataset(train_df, tokenizer)\n",
    "valid_encoded = encode_dataset(valid_df, tokenizer)\n",
    "test_encoded  = encode_dataset(test_df, tokenizer)\n",
    "test_label_encoded = encode_dataset(test_label_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b87f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_encoded, batch_size=32, shuffle=True, num_workers=8,\n",
    "    collate_fn=lambda x: collate_fn(x, max_seq_len=512)\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_encoded, batch_size=32, shuffle=False, num_workers=8,\n",
    "    collate_fn=lambda x: collate_fn(x, max_seq_len=512)\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_encoded, batch_size=32, shuffle=False, num_workers=8,\n",
    "    collate_fn=lambda x: collate_fn(x, max_seq_len=512)\n",
    ")\n",
    "\n",
    "test_label_loader = DataLoader(\n",
    "    test_label_encoded, batch_size=32, shuffle=False, num_workers=8,\n",
    "    collate_fn=lambda x: collate_fn(x, max_seq_len=512)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9b1cad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'positive': 0, 'neutral': 1, 'negative': 2}\n",
      "{0: 'positive', 1: 'neutral', 2: 'negative'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "fb87ffd0-f0cd-49b1-ad7b-7b6ee7367410",
       "rows": [
        [
         "0",
         "warung ini dimiliki oleh pengusaha pabrik tahu yang sudah puluhan tahun terkenal membuat tahu putih di bandung . tahu berkualitas , dipadu keahlian memasak , dipadu kretivitas , jadilah warung yang menyajikan menu utama berbahan tahu , ditambah menu umum lain seperti ayam . semuanya selera indonesia . harga cukup terjangkau . jangan lewatkan tahu bletoka nya , tidak kalah dengan yang asli dari tegal !",
         "0"
        ],
        [
         "1",
         "mohon ulama lurus dan k212 mmbri hujjah partai apa yang harus diwlh agar suara islam tidak pecah-pecah",
         "1"
        ],
        [
         "2",
         "lokasi strategis di jalan sumatera bandung . tempat nya nyaman terutama sofa di lantai 2 . paella nya enak , sangat pas dimakan dengan minum bir dingin . appetiser nya juga enak-enak .",
         "0"
        ],
        [
         "3",
         "betapa bahagia nya diri ini saat unboxing paket dan barang nya bagus ! menetapkan beli lagi !",
         "0"
        ],
        [
         "4",
         "duh . jadi mahasiswa jangan sombong dong . kasih kartu kuning segala . belajar dulu yang baik , tidak usahlah ikut-ikut politik . nanti sudah selesai kuliah nya mau ikut politik juga tidak telat . dasar mahasiswa .",
         "2"
        ],
        [
         "5",
         "makanan beragam , harga makanan di food stall akan ditambahkan 10 % lagi di kasir , suasana ramai dan perlu perhatian untuk mendapatkan parkir dan tempat duduk .",
         "0"
        ],
        [
         "6",
         "pakai kartu kredit bca tidak untung malah rugi besar",
         "2"
        ],
        [
         "7",
         "tempat unik , bagus buat foto , makanan enak , pegawai ramah , bersih dan luas , wifi kencang . harga standar dan sesuai dengan tempat nya . ada menu masakan makanan barat dan indonesia . menu favorit lychee mojito dan spagheti",
         "0"
        ],
        [
         "8",
         "saya bersama keluarga baru saja menikmati pengalaman kuliner yang menyenangkan di rm sari sunda di jalan . setiabudhi , bandung . tapi , karena tidak ada hubungan untuk rm sari sunda di jalan . setiabudhi , maka saya tuliskan di sini . jadi , maaf jika rekan-rekan pembaca ada yang bingung . beberapa hal yang saya suka dari restoran ini adalah bahwa pelayanan restoran ini terbilang cepat .",
         "0"
        ],
        [
         "9",
         "bersyukur",
         "0"
        ],
        [
         "10",
         "simcard indosat inaktiv gara-gara lupa isi pulsa dan kabar nya aktif jika pinda ke pasca bayar , ribet banget",
         "2"
        ],
        [
         "11",
         "sifat iri sering muncul pada orang orang yang tidak punya tujuan hidup",
         "2"
        ],
        [
         "12",
         "sekadar menceritakan pengalaman saya pesan steak grilled beef 200 tidak disajikanlah steak 200 tidak tersebut dalam 2 potongan 100 tidak - 100 tidak rasanya tidak buruk , namun kualitas daging nya yang membuat saya enggan memesan menu beef lagi khusus nya sirloin karena lemak nya terlalu banyak untuk ukuran steak namun , masih ada menu-menu lain yang sangat menempel di lidah saya sarankan untuk membeli menu berlabel cheese atau . lanjutan",
         "0"
        ],
        [
         "13",
         "pengalaman bersama indosat hari ini , semoga tidak terjadi pada pelanggan lain . sempat sampai marah-marah dengan pelayanan pelanggan indosat",
         "2"
        ],
        [
         "14",
         "anak sekarang sulit untuk dinasehati",
         "2"
        ],
        [
         "15",
         "hanya mengatasi masalah kayak gini saja anies sandi tidak becus . ke mana saja pasukan kebersihan yang begitu banyak jumlah nya ?",
         "2"
        ],
        [
         "16",
         "setiap bumn dibentuk dengan uu bukan dibentuk dengan uu .",
         "1"
        ],
        [
         "17",
         "sehabis puas bermain di trans studio bandung , saya bersama teman sepakat untuk makan ayam kakek di sini . ayam nya selalu enak dan gurih !",
         "0"
        ],
        [
         "18",
         "rasa bakso cuanki dan batagor cukup . selalu ramai pengunjung . buka sekitar jam 10 pagi . dari jalan riau menuju jalan a yani ada sisi kiri jalan sekitar jalan anggrek . harga per porsi sekitar rp 14 000 . datanglah lebih awal karena selalu ramai pengunjung",
         "0"
        ],
        [
         "19",
         "sgwr 2018 beri dampak positif terhadap hobi anak-anak",
         "0"
        ],
        [
         "20",
         "berada di lembang , pemandangan indah , udara sejuk , penataan resto yang bagus , dilengkapi dengan makanan yang sangat nikmat . pilihan menu beragam dan minuman yang lengkap . lingkungan yang cocok untuk makan berdua dengan pasangan , membawa keluarga ataupun bersama dengan teman . lapangan parkir luas . restoran yang berkonsep terbuka ini membuat udara lembang sangat terasa sejuk nya .",
         "0"
        ],
        [
         "21",
         "berbuka puasa di sini pada minggu lepas , pak supir yang mencadangkan tempat makan ini . makanan nya di sini sedap dan harga berpatutan . tempat nya luas dan cantik . rekomendasi too others to dine in here to rasa authentic sunda makanan indonesia .",
         "0"
        ],
        [
         "22",
         "hahaha suka banget nonton kartun indonesia keluarga pak tomat",
         "0"
        ],
        [
         "23",
         "bagi teman-teman yang sedang berkunjung ke bandung bisa mampir ke kopi anjis untuk makan makanan yang tidak terlalu berat . ada cilok rakyat ditemankan dengan teh sereh dan lekker .",
         "0"
        ],
        [
         "24",
         "di restoran ini , saya dan keluarga makan malam yang terakhir di bandung . kami berjumlah 8 orang dan bila nya hanya sekitar 400 an , benar-benar murah meriah , sampai makan double-double lagi . makanan nya juga enak , suasana kafe menarik , pelayanan sangat bagus . saya masih teringat petunjuk toilet yang ada di restoran ini men to the pergi , karena momen are selalu ribut hahahaha . setimpal .",
         "0"
        ],
        [
         "25",
         "alhamdulillah hari ini tidak ke jalan bugel agak kesal juga kalau tiap hari lewat sana melulu . sempit , dua arah , macet sudah jadi makanan sehari-hari",
         "2"
        ],
        [
         "26",
         "respon agak lama , sama sayang nya rem nya bukan asli , masih rom distrobitor",
         "2"
        ],
        [
         "27",
         "lokasi dengan pemandangan alam yang masih natural dan indah . suasana juga sejuk dan tenang . hanya saja banyak nyamuk dan harga makanan relatif mahal .",
         "0"
        ],
        [
         "28",
         "pdip sebut ridwan kamil menang karena berbaju merah",
         "1"
        ],
        [
         "29",
         "malu - maluin nih oknum yang tidak bertanggung jawab .",
         "2"
        ],
        [
         "30",
         "makan siang di sini asyik juga . nuansa bali walaupun music nya musik sunda kadang musik khas bali bergantian . tempat nya enak dan adem tapi sayang sekali pesan kopi lama banget datang nya , diminta berkali kali , iya pak iya pak hampir 1 jam dan ketika kopi datang pun bukan kopi panas tapi kopi ade , ini kah ciri khas kopi di sini . kalau khas nya kopi dingin tidak enak .",
         "2"
        ],
        [
         "31",
         "tempat steak di bandung sejak lama dari zaman setiabudi sampai sekarang buka cabang di riau . tempat di riau ini lebih besar , parkiran juga tidak sulit seperti di setiabudi . lokasi di tempat kuliner jalan riau . porsi dan harga nya pas untuk ukuran steak . untuk zoom non smoking nya nyaman .",
         "0"
        ],
        [
         "32",
         "08:30 : kedatangan presiden ri dan rombongan di gate 2 , terminal 3 disambut oleh menteri perhubungan , menteri bumn , gubernur banten , dirjen perkeretaapian kemhub , dirut ap2 , dirut pt kami , dan dirut railink",
         "1"
        ],
        [
         "33",
         "makanan tradisional yang selalu rasanya stabil iga garang asam nya dan java steak nya jangan lupa ya dicoba hidangan penutup semua kue enak lemper soes fla gulung . enak sekali tidak ada yang tidak enak kalau makanan di sini .",
         "0"
        ],
        [
         "34",
         "sampai saat ini saya rasa batagor ini masih yang terenak di kota bandung dibandingkan dengan batagor lainnya yang saya pernah coba . bumbu kacang nya pas rasanya di lidah , dan batagor nya juga tidak amis bau nya . silakan mencoba untuk yang belum pernah coba .",
         "0"
        ],
        [
         "35",
         "aroma khas yang ada jika makan di atas daun pisang , ya walau ramai tempat ini selalu jadi favourit saya jika ke bandung .",
         "0"
        ],
        [
         "36",
         "akhir tahun lalu saya dan keluarga berjalan ke daerah lembang dan tidak sengaja mampir makan di resto ini . suasana nya nyaman , pelayanan juga ramah dan berlebihan ala kami puas . makanan yang di sajikan standar seperti makanan di restoran pada umum nya , tetapi yang membuat berbeda adalah sambal stroberi yang yummy dan bikin ketagihan . di sana selain bisa makan kita juga bisa sambil memetik . lanjutan",
         "0"
        ],
        [
         "37",
         "risma menjatuhkan pilihan nya pada gus ipul - puti di pilgub jatim 2018 ini .",
         "1"
        ],
        [
         "38",
         "pengalaman yang cukup seru , makan tanpa alas piring , tapi hanya dengan alas daun , makin nikmat . makanan sunda yang sangat bervariatif dan cukup enak . tips nya : jangan terbawa emosi dan kalap memesan dan memilih semua makanan yang disediakan biasanya kalap kalau sudah melihat makanan macam-macam begitu . pilih seperlunya .",
         "0"
        ],
        [
         "39",
         "makanan nya enak , suasana nyaman . harga bisa dibilang sama dengan tempat lain . restoran ini ada 4 konsep tapi yang paling terkenal menu jepang nya yang enak loh",
         "0"
        ],
        [
         "40",
         "kampung daun adalah tempat makan yang menyatukan konsep alam dan budaya dari daerah setempat . walaupun di dalam kompleks perumahan akan tetapi tempat tersebut cukup luas mempunyai mungkin sekitar 20 lebih saung / tempat makan dari yang kapasitas sedang hingga besar . kualitas makanan enak dan dengan ada nya suara riak air dari air terjun kecil di sana membuat suasana sangat nyaman untuk makan .",
         "0"
        ],
        [
         "41",
         "waktu itu ke sini pesan nasi goreng dan kentang goreng , nasi goreng nya semua suka . kentang goreng nya enak banget , dan presentasi nya bagus . keluarga bilang kopi nya enak . hal yang sangat baik di sini adalah tempat nya luas dan yang di luar bisa lihat pemandangan dusun bambu , tapi pelayanan nya tidak cepat sehingga saya harus bertanya beberapa kali tentang pesanan saya . harga nya cukup mahal , namun karena makanan nya enak semua jadi terbayarkan . tidak perlu pikir dua kali jika mau ke tempat ini lagi .",
         "0"
        ],
        [
         "42",
         "banyak sekali tempat makan sunda yang bertebaran di kota bandung , tetapi tidak tahu kenapa saya sangat jatuh hati dengan sebuah warung makan ini . ibu imas yang berada di dekat alun-alun kota bandung menyuguhkan rumah makan sunda dengan karakter warung nasi zaman dahulu yang di mana kita bisa mengambil semua hidangan di depan kita tanpa harus melalui proses order yang biasa kita jumpai di warung makan .",
         "0"
        ],
        [
         "43",
         "hai tolong bantu saya tidak bisa input tidak resi jne dan kenomor resi sudah dipakai .",
         "1"
        ],
        [
         "44",
         "foods : menu baru cheeseburger nya oke banget dan chicken wings pizza hut memang selalu juara . dirilis : mixing green tea yakult , perfect ! satu-satunya kekurangan pizza hut adalah pinggiran nya ,",
         "0"
        ],
        [
         "45",
         "dusun bambu ini tergolong baru di bandung . tempat nya yang dekat banget sama almamater saya . membuat saya gampang cari ini tempat . pemandangan nya bagus . banyak tempat makan yang enak-enak . beli nya nanti pakai voucher .",
         "0"
        ],
        [
         "46",
         "tidak memuaskan",
         "2"
        ],
        [
         "47",
         "suruh ngaca pemain nya ! dasar oneng ! ngomong saja masih ala betawi lu ! kampungan !",
         "2"
        ],
        [
         "48",
         "kafe ini menyajikan sensasi makan dalam gelap . cukup unik sih , tetapi lebih dari sekali , rasanya orang jarang datang lagi . hanya menarik untuk sekadar mencoba .",
         "2"
        ],
        [
         "49",
         "sesuai dengan nama nya mi awie , kedai makan ini menyediakan menu mi dengan olahan daging babi . selain mi masih ada pilihan lainnya seperti nasi goreng babi , capjay goreng , bakso , pangsit dan lainnya . kami mencoba menu mi babi casau special , rasanya . enak banget !",
         "0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 11000
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>tidak kecewa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>enak rasa masakan nya apalagi kepiting yang me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>hormati partai-partai yang telah berkoalisi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>pagi pagi di tol pasteur sudah macet parah , b...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>meskipun sering belanja ke yogya di riau junct...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment\n",
       "0      warung ini dimiliki oleh pengusaha pabrik tahu...          0\n",
       "1      mohon ulama lurus dan k212 mmbri hujjah partai...          1\n",
       "2      lokasi strategis di jalan sumatera bandung . t...          0\n",
       "3      betapa bahagia nya diri ini saat unboxing pake...          0\n",
       "4      duh . jadi mahasiswa jangan sombong dong . kas...          2\n",
       "...                                                  ...        ...\n",
       "10995                                       tidak kecewa          0\n",
       "10996  enak rasa masakan nya apalagi kepiting yang me...          0\n",
       "10997        hormati partai-partai yang telah berkoalisi          1\n",
       "10998  pagi pagi di tol pasteur sudah macet parah , b...          2\n",
       "10999  meskipun sering belanja ke yogya di riau junct...          0\n",
       "\n",
       "[11000 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i, i2w = LABEL2INDEX, INDEX2LABEL\n",
    "print(w2i)\n",
    "print(i2w)\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b4bc087",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=5e-6)\n",
    "model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5648aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_sequence_classification(model, batch_data, i2w, is_test=False, device='cpu'):\n",
    "    \"\"\"\n",
    "    Forward function for sequence classification.\n",
    "    \n",
    "    Parameters:\n",
    "        model      : torch.nn.Module\n",
    "        batch_data : tuple of (input_ids, attention_mask, [token_type_ids], labels)\n",
    "        i2w        : dict, index to label mapping\n",
    "        is_test    : bool, whether test mode (optional)\n",
    "        device     : str or torch.device\n",
    "    \n",
    "    Returns:\n",
    "        loss       : torch.Tensor\n",
    "        list_hyp   : list of predicted labels\n",
    "        list_label : list of ground truth labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # Move data to tensors\n",
    "    if len(batch_data) == 3:\n",
    "        input_ids, attention_mask, labels = batch_data\n",
    "        token_type_ids = None\n",
    "    else:\n",
    "        input_ids, attention_mask, token_type_ids, labels = batch_data\n",
    "    \n",
    "    input_ids = torch.as_tensor(input_ids).to(device)\n",
    "    attention_mask = torch.as_tensor(attention_mask).to(device)\n",
    "    labels = torch.as_tensor(labels).to(device)\n",
    "    \n",
    "    if token_type_ids is not None:\n",
    "        token_type_ids = torch.tensor(token_type_ids).to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(\n",
    "        input_ids, \n",
    "        attention_mask=attention_mask, \n",
    "        token_type_ids=token_type_ids, \n",
    "        labels=labels\n",
    "    )\n",
    "    loss, logits = outputs[:2]\n",
    "\n",
    "    # Get predictions\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    \n",
    "    list_hyp = [i2w[p.item()] for p in preds]\n",
    "    list_label = [i2w[l.item()] for l in labels]\n",
    "\n",
    "    return loss, list_hyp, list_label\n",
    "\n",
    "def document_sentiment_metrics_fn(list_hyp, list_label):\n",
    "    metrics = {}\n",
    "    metrics[\"ACC\"] = accuracy_score(list_label, list_hyp)\n",
    "    metrics[\"F1\"] = f1_score(list_label, list_hyp, average='macro')\n",
    "    metrics[\"REC\"] = recall_score(list_label, list_hyp, average='macro')\n",
    "    metrics[\"PRE\"] = precision_score(list_label, list_hyp, average='macro')\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab072de",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 6\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    torch.set_grad_enabled(True)\n",
    "\n",
    "    total_train_loss = 0\n",
    "    list_hyp, list_label = [], []\n",
    "\n",
    "    train_pbar = tqdm(train_loader, leave=True, total=len(train_loader))\n",
    "    for i, batch_data in enumerate(train_pbar):\n",
    "        # Forward model\n",
    "        loss, batch_hyp, batch_label = forward_sequence_classification(\n",
    "            model, batch_data[:-1], i2w=i2w, device='cpu'\n",
    "        )\n",
    "\n",
    "        # Update model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tr_loss = loss.item()\n",
    "        total_train_loss += tr_loss\n",
    "\n",
    "        # Track predictions\n",
    "        list_hyp += batch_hyp\n",
    "        list_label += batch_label\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        train_pbar.set_description(\n",
    "            f\"(Epoch {epoch+1}) TRAIN LOSS:{total_train_loss/(i+1):.4f} LR:{current_lr:.8f}\"\n",
    "        )\n",
    "\n",
    "    # Train metrics\n",
    "    metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
    "    print(f\"(Epoch {epoch+1}) TRAIN LOSS:{total_train_loss/(i+1):.4f} {metrics_to_string(metrics)} \"\n",
    "        f\"LR:{current_lr:.8f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    total_loss = 0\n",
    "    list_hyp, list_label = [], []\n",
    "\n",
    "    pbar = tqdm(valid_loader, leave=True, total=len(valid_loader))\n",
    "    for i, batch_data in enumerate(pbar):\n",
    "        loss, batch_hyp, batch_label = forward_sequence_classification(\n",
    "            model, batch_data[:-1], i2w=i2w, device='cpu'\n",
    "        )\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        list_hyp += batch_hyp\n",
    "        list_label += batch_label\n",
    "\n",
    "        metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
    "        pbar.set_description(\n",
    "            f\"VALID LOSS:{total_loss/(i+1):.4f} {metrics_to_string(metrics)}\"\n",
    "        )\n",
    "\n",
    "    metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
    "    print(f\"(Epoch {epoch+1}) VALID LOSS:{total_loss/(i+1):.4f} {metrics_to_string(metrics)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1990f5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:25<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Metrics | ACC:0.91 F1:0.89 REC:0.87 PRE:0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test\n",
    "model.load_state_dict(torch.load(\"../backend/model/indobert_sentiment.pt\", map_location='cpu'))\n",
    "model.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "total_loss, total_correct, total_labels = 0, 0, 0\n",
    "list_hyp, list_label = [], []\n",
    "\n",
    "pbar = tqdm(test_loader, leave=True, total=len(test_loader))\n",
    "for i, batch_data in enumerate(pbar):\n",
    "    _, batch_hyp, batch_label = forward_sequence_classification(model, batch_data[:-1], i2w=i2w, device='cpu')\n",
    "    list_hyp += batch_hyp\n",
    "    list_label += batch_label\n",
    "metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
    "print(\"TEST Metrics | {}\".format(metrics_to_string(metrics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a9ec7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:29<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index     label\n",
      "0        0  negative\n",
      "1        1  negative\n",
      "2        2  negative\n",
      "3        3  negative\n",
      "4        4  negative\n",
      "..     ...       ...\n",
      "495    495   neutral\n",
      "496    496   neutral\n",
      "497    497   neutral\n",
      "498    498  positive\n",
      "499    499  positive\n",
      "\n",
      "[500 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test\n",
    "model.load_state_dict(torch.load(\"../backend/model/indobert_sentiment.pt\", map_location='cpu'))\n",
    "model.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "total_loss, total_correct, total_labels = 0, 0, 0\n",
    "list_hyp, list_label = [], []\n",
    "\n",
    "pbar = tqdm(test_label_loader, leave=True, total=len(test_label_loader))\n",
    "for i, batch_data in enumerate(pbar):\n",
    "    _, batch_hyp, batch_label = forward_sequence_classification(model, batch_data[:-1], i2w=i2w, device='cpu')\n",
    "    list_hyp += batch_hyp\n",
    "\n",
    "# Save Prediction\n",
    "df = pd.DataFrame({'label':list_hyp}).reset_index()\n",
    "df.to_csv('pred.csv', index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5b8b6e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'sentiment', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Combine and compare with true\n",
    "print(test_df.columns)\n",
    "\n",
    "combined_test_df = test_df\n",
    "combined_test_df['sentiment'] = combined_test_df['sentiment'].apply(lambda lab: i2w[lab])\n",
    "combined_test_df['label'] = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8bb41650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "74e01072-a2c3-43bf-ab6c-cd7911252585",
       "rows": [
        [
         "0",
         "kemarin gue datang ke tempat makan baru yang ada di dago atas . gue kira makanan nya enak karena harga nya mahal . ternyata , boro-boro . tidak mau lagi deh ke tempat itu . sudah mana tempat nya juga tidak nyaman banget , terlalu sempit .",
         "negative",
         "negative"
        ],
        [
         "1",
         "kayak nya sih gue tidak akan mau balik lagi ke tempat itu . gila , ya , gue enggak ngerti kenapa tempat nya dibiarkan panas . sudah begitu kotor pula . kalau panas kepanasan , kalau hujan kehujanan . harus nya sih tidak ada restoran yang kayak gitu . tidak tahu deh apa yang mereka jual .",
         "negative",
         "negative"
        ],
        [
         "2",
         "kalau dipikir-pikir , sebenarnya tidak ada yang bisa dibanggakan dari jokowi . pertama , dia tidak bisa nepatin janji . kedua , kerjaan nya selalu pencitraan . ketiga , dia tidak pro rakyat . sudahlah . ku sudah terlanjur kecewa .",
         "negative",
         "negative"
        ],
        [
         "3",
         "ini pertama kalinya gua ke bank buat ngurusin pembuatan rekening baru . nama nya juga orang pertama kali ya baru ke bank , gua kena semprot . kelihatan banget pelayanan pelanggan - nya tidak suka gua banyak bertanya . amit-amit . padahal itu kan tugas mereka buat melayangkan gua !",
         "negative",
         "negative"
        ],
        [
         "4",
         "waktu sampai dengan gue pernah disuruh ibu latihan karate . kata nya biar gue bisa melawan penjahat kalau ada laki-laki iseng , tapi di hari pertama latihan , kaki gue langsung cedera . jadilah sekarang trauma dan tidak mau sekali-sekali buat latihan karate lagi .",
         "negative",
         "negative"
        ],
        [
         "5",
         "pelayanan di hotel salak bogor tidak sebagus yang gue membayangkan . fasilitas nya juga biasa banget padahal kata nya hotel bintang lima . hm . kecewa . kayak nya sih nanti-nanti tidak mau ke sana lagi .",
         "negative",
         "negative"
        ],
        [
         "6",
         "ada apa dengan young lex ? kenapa dia harus mengirim hal-hal tidak berfaedah kayak gitu . merusak moral banget sumpah !",
         "negative",
         "negative"
        ],
        [
         "7",
         "gue pesimis sama manusia , terutama dalam ngurusin sampah . sudah berapa banyak hewan-hewan laut jadi korban gara-gara kita buang sampah ke laut . tidak tega gue liat nya . kadang tidak mengerti juga sebenarnya pemimpin-pemimpin yang ada itu pada mikirin enggak sih urusan penting kayak gini . he .",
         "negative",
         "negative"
        ],
        [
         "8",
         "saya kecewa karena pengeditan biodata penumpang dilakukan by sistem tanpa konfirmasi dan solusi permasalahan nya pun dianggap sepele karena dibiarkan begitu saja sedang pelayanan pelanggan yang sudah berkali-berkali dihubungi pun hanya seperti mengulur waktu . sampai detik ini belum ada solusi untuk masalah saya yang kesalahan nya sendiri bukan dari pihak saya .",
         "negative",
         "negative"
        ],
        [
         "9",
         "saya hari ini melakukan pemesanan dan tiket saya tidak kunjung saya terima . padahal saya sudah menelpon pelayanan pelanggan , sudah mengirimkan email dengan bukti transfer tapi respon nya sangat lambat dan tidak jelas .",
         "negative",
         "negative"
        ],
        [
         "10",
         "sangat merugikan , saya sudah memesan dan membayar tetapi e - tiket tidak ada juga , padahal bukti pembayaran sudah jelas , sudah menelepon pelayanan pelanggan berkali kali dan tidak ada solusi nya , pulsa sudah habis ratusan ribu , saya meminta kembalikan uang juga sangat lama proses nya , sangat merugikan pengguna , banyak kerugian uang transport , waktu , penginapan dll.",
         "negative",
         "negative"
        ],
        [
         "11",
         "saya itu memesan tiket dot com . sudah dibayar email belum ada balasan . bukti pembayaran sudah saya kirim by email . saya masukkan data balasan nya pemesanan kadaluarsa terus . akhirnya saya beli lagi langsung ke loket . saya minta uang kembali masih menunggu 3 - 14 hari . ambil saja uang tiket nya tidak apa-apa . sedih saya download aplikasi ini .",
         "negative",
         "negative"
        ],
        [
         "12",
         "saya sudah bayar tetapi etiket tidak dikirim malah kadaluwarsa , diminta struk pembayaran saya sudah tidak punya hanya sms banking . tetapi tetap saja tidak digubris dari pelayanan pelanggan - nya . sudah email dan telepon berkali-berkali tetap tidak ada hasil . sangat mengecewakan .",
         "negative",
         "negative"
        ],
        [
         "13",
         "saya mesan tiket tapi tidak dikonformasi dan proses pengembalian uang yang tidak jelas dan belum ada sampai sekarang , pelayanan nya yang sangat buruk dan saran saya jangan pesan di sini , sangat mengecewakan .",
         "negative",
         "negative"
        ],
        [
         "14",
         "sangat kecewa dengan aplikasi ini , sudah ditransfer tetapi etiket tidak dikirim saya coba telepon call centre seharian tetapi sibuk terus call genre nya , mending pakai traveloka adalah untuk pesanan selanjutnya .",
         "negative",
         "negative"
        ],
        [
         "15",
         "melihat komen nya 90 % negatif jadi pikir-pikir buat mencari tiket kereta di sini . mending aplikasi yang lain saja yang sudah terbukti bagus bertahun-bertahun .",
         "negative",
         "negative"
        ],
        [
         "16",
         "aplikasi tukang bohong . promo gratis makan tidak terjadi . komplain ke pelayanan pelanggan dengan email tidak ditanggapi . komplain by phone hanya dicatat saja tidak ada tindak lanjut . sangat tidak direkomendasikan untuk siapa pun .",
         "negative",
         "negative"
        ],
        [
         "17",
         "kata nya dapat promo 100 ribu . tapi setelah di bayar di atm - nya ternyata harga normal . sudah saya kirim email tapi tidak ada balasan . mengecewakan .",
         "negative",
         "negative"
        ],
        [
         "18",
         "saya sudah bayar untuk hotel tapi etiket tidak terbit , saya sudah kirim email bukti pembayaran nya tapi tetap tidak ada mengikuti naik - nya . sampai hari h mau cek - in ini . sudah menghubungi bolak balik pelayanan pelanggan sama saja ngulang-ngulang informasi dari awal . dijanjikan akan ditelpon tapi tidak dihubungi juga sampai sekarang . saya mau laporkan polisi . menyebalkan .",
         "negative",
         "negative"
        ],
        [
         "19",
         "saya kecewa karena saya sudah transfer dan belum dikonfirmasi saya telepon malah pelanggan sibuk terus , aduh kecewa nih gue .",
         "negative",
         "negative"
        ],
        [
         "20",
         "saya sudah transfer ratusan ribu dan sesuai nominal transfer . tapi tiket belum muncul juga . harus diwaspadai ini aplikasi ini . bahaya .",
         "negative",
         "negative"
        ],
        [
         "21",
         "pelayanan pelanggan tidak respon , komentar disuruh email , email saya tidak ditanggapi , sudah beberapa hari yang lalu , sampai sekarang tidak ada respon . menyusahkan saja .",
         "negative",
         "negative"
        ],
        [
         "22",
         "tolong untuk pelayana nya diperjelas ya . sudah pesan tiket sudah dibayar tetapi dengan alasan bank bermasalah dan tidak ada pertanggungjawaban untuk memulangkan uang saja harus sampai ditelpon lagi . dikirim by email untuk komponen tidak direspon . kecewa .",
         "negative",
         "negative"
        ],
        [
         "23",
         "luar biasa kecewa sangat dengan aplikasi ini , saya sudah hubungi pusat panggilan untuk cek pemesanan saya karena saya sudah bayar dan tidak muncul e - tiket nya , bahkan saya sudah kirim bukti transaksi nya ke e-mail , hingga saat ini tidak ada pihak pusat panggilan yang menghubungi , kecewa .",
         "negative",
         "negative"
        ],
        [
         "24",
         "sangat mengecewakan , saya pesan tiket dan sudah saya bayar , padahal waktu itu belum kadaluarsa pas saya transfer , tapi sampai sekarang belum dikasih kode bokong nya , malah dikasih notifikasi sudah kadaluarsa , lalu uang nya lari nya ke mana , pas saya hubungi lewat email hanya ditanggapi sekali saja .",
         "negative",
         "negative"
        ],
        [
         "25",
         "tolong jangan order tiket pakai aplikasi ini kalau tidak mau kecewa . benci banget . sudah transfer etiket tidak dikirim-kirim malah pesanan dibatalkan . telpon pelayanan pelanggan juga tidak diangkat . di-email tidak dibalas .",
         "negative",
         "negative"
        ],
        [
         "26",
         "saya pesan tiket pesawat dan sudah melakukan pembayaran sesuai instruksi namun sudah lebih dari 4 jam belum ada terbit e - tiket malahan status pesanan saya malah jadi pemesanan kadaluarsa . komplain sudah saya lakukan melalui email dan telpon pelayanan pelanggan sampai sekarang belum ada penyelesaian yang berarti . ini sangat merugikan .",
         "negative",
         "negative"
        ],
        [
         "27",
         "saya pesan ticket sampai sekarang tidak ada konformasi nya . uang sudah ditransfer , kalau seperti itu kembalikan uang nya , tai sekali , telepon pusat panggilan habis pulsa hampir 200 . tidak ada . kembalikan uang saya . jangan pernah kalian pesan tiket di sini . menyesal",
         "negative",
         "negative"
        ],
        [
         "28",
         "pembayaran sudah dilakukan tetapi e - tiket tidak dikirim-dikirim malah dipesan diblang kadaluarsa . titip cs nya berkali-berkali jwaban nya tidak ada yang membantu dan tidak sinkron semua . sampai sekarang belum jelas pengembalian uang ataupun penggantian tiket . disarankan tidak usah memakai aplikasi ini .",
         "negative",
         "negative"
        ],
        [
         "29",
         "sangat mengecewakan ! di mana kalau pesan tiket sudah dibayar sudah dikasih bukti transfer itu langsung dikasih nomor e - tiket nya . ini kok tidak ada konfirmasi apa , sudah mendekati hari h tiba pesanan kadaluarsa . pelayanan sangat buruk ! pelayanan pelanggan - nya juga tidak sopan . segera kembalikan uang pengembalian dana tiket saya !",
         "negative",
         "negative"
        ],
        [
         "30",
         "saya sudah komplain dengan berbagai cara tapi sangat tidak mengenakkan , selain lama respon tetapi juga tidak ditanggapi . saya sudah transfer uang dan sudah saya kirim tanda bukti nya tapi sampai saat ini tidak ada kejelasan sama sekali . saya merasa tertipu .",
         "negative",
         "negative"
        ],
        [
         "31",
         "saya hilang 2.5 juta dari apa ini karena , terjadi eror saat melanjutkan pembayaran yang terpending menyebabkan isi-isi data penumpang dan terjadi kesalahan flight . kecewa sekali dengan fasilitas yang ada .",
         "negative",
         "negative"
        ],
        [
         "32",
         "sudah melakukan pembayaran tetapi tiket ada , bukti transfer sudah dilampirkan ke email dengan alasan uang belum diterima , ini niat jualan apa mau mengambil uang orang ? tidak lagi-lagi beli tiket di tiket.com , sumpah asli tipu dan produk sampah",
         "negative",
         "negative"
        ],
        [
         "33",
         "saya baru saja mengalami pesan tiket lewat ini aplikasi penipu . sudah transfer uang . tapi belum ada balasan . dan tidak ada respon . jangan pernah pakai aplikasi tak nii .",
         "negative",
         "negative"
        ],
        [
         "34",
         "biasanya pesan tiket pesawat lancar-lancar saja . terakhir beli tiket kereta eksekutif untuk 6 orang sudah ditransfer sebelum waktu berakhir tetapi cek order pemesanan kadaluarsa . menyebalkan !",
         "negative",
         "negative"
        ],
        [
         "35",
         "proses pengembalian dana lama . sudah dibayar tapi kode pesan tidak dapat . pelayanan kurang , telepon ke pelayanan pelanggan pakai pulsa yang banyak . tidak mau pesan lagi di sini",
         "negative",
         "negative"
        ],
        [
         "36",
         "e - tiket belum diterima padahal uang nya sudah ditransfer . pas mau konfirmasi ke pelayanan pelanggan tidak pernah direspons , e-mail juga tidak dijawab . mantap ! bikin kecewa saja bisa nya !",
         "negative",
         "negative"
        ],
        [
         "37",
         "saya sudah berhasil transaksi sesuai nominal tagihan . dan sampai saat ini belum dapat etiket . ini pelayanan yang sangat buruk dan menjengkelkan . sudah email beberapa kali tapi tidak ada respon . pelayanan pelanggan nya yang super duper lemah otak . kalau kode pesan tidak juga dikirim . pokokanyak duit saya harus kembali .",
         "negative",
         "negative"
        ],
        [
         "38",
         "tidak bisa menggunakan kode promo di aplikasi android , telpon ke pelayanan pelanggan bilang nya tidak ada solusi nya . oke uninstall dan tidak rekomendasi !",
         "negative",
         "negative"
        ],
        [
         "39",
         "menyesal pesan tiket pesawat di tiket.com sudah di transfer dibilang transaksi kedaluarsa , pulsa habis banyak untuk telpon pelayanan pelanggan .",
         "negative",
         "negative"
        ],
        [
         "40",
         "di saat saya salah pembelian , pengembalian uang cuma 50 %, itu tidak masalah abang saya . tetapi sudah 2 bulan belum ada juga pengembalian nya , tiket.com tidak bisa dipercaya .",
         "negative",
         "negative"
        ],
        [
         "41",
         "sangat kecewa dengan pelayanan nya saya sudah transfer tapi sampai sekarang belum ada konfirmasi padahal sudah kirim bukti transfer dan sudah telpon ke cs nya .",
         "negative",
         "negative"
        ],
        [
         "42",
         "saya kecewa sama aplikasi ini padahal cek - in-nya jam 19.30 . malahan saya ketinggal pesawat . kembalikan uang saya .",
         "negative",
         "negative"
        ],
        [
         "43",
         "tiket kadaluarsa padahal sudah bayar . kacau . mengganggu waktu dan rencana saya . sistem nya tidak bagus . pelayanan pelanggan - nya tidak professional . kalau tidak mau kerja suruh jangan kerja .",
         "negative",
         "negative"
        ],
        [
         "44",
         "maaf ya saya uninstall . saya kecewa karena sudah melakukan pembayaran tetapi tidak dikonfirmasi . saya sudah komplain via email tetapi respon nya sangat lambat .",
         "negative",
         "negative"
        ],
        [
         "45",
         "serem melihat pengalaman yang sudah pesan di sini . mending uninstal saja . aplikasi abal-abal ini . mending pakai burung biru saja . jelas ...... !!",
         "negative",
         "negative"
        ],
        [
         "46",
         "minta dikembalikan karena permasalahan bencana alam tapi tidak ada respon baik dari pelanggan nya . sangat mengecewakan .",
         "negative",
         "negative"
        ],
        [
         "47",
         "aplikasi tipu . sialan . mengembalikan duit gua . gua minta prtnggungjawaban susah sekali sialan . menyebalkan .",
         "negative",
         "negative"
        ],
        [
         "48",
         "saya kemarin batalkan tiket pesawat karena salah ordrer , kami sudah minta dikembalikan dan dapat balasan baru diproses . tapi kenapa proses lama tidak seperti traveloka saat itu langsung dikembalikan , pelayanan pelanggan pun telepon nya tarif mahal . ini sudah lebih tiga hari setelah saya baca ternyata banyak pelanggan yang dibuat kecewa .",
         "negative",
         "negative"
        ],
        [
         "49",
         "tolong ya dana pengembalian dana saya ini sudah berbulan bulan saya email berkali kali tidak dibalas masalah nya ini bukan ratusan ribu atau satu dua jutaan ! sama sekali tidak bertanggung jawab dan sangat mengecewakan",
         "negative",
         "negative"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 500
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kemarin gue datang ke tempat makan baru yang a...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kayak nya sih gue tidak akan mau balik lagi ke...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kalau dipikir-pikir , sebenarnya tidak ada yan...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ini pertama kalinya gua ke bank buat ngurusin ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>waktu sampai dengan gue pernah disuruh ibu lat...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>kata nya tidur yang baik itu minimal enam jam ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>indonesia itu ada di benua asia .</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>salah satu kegemaran anak remaja indonesia sek...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>melihat warna hijau bisa bikin mata jadi lebih...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>bondan winarno yang suka bilang maknyus sekara...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text sentiment     label\n",
       "0    kemarin gue datang ke tempat makan baru yang a...  negative  negative\n",
       "1    kayak nya sih gue tidak akan mau balik lagi ke...  negative  negative\n",
       "2    kalau dipikir-pikir , sebenarnya tidak ada yan...  negative  negative\n",
       "3    ini pertama kalinya gua ke bank buat ngurusin ...  negative  negative\n",
       "4    waktu sampai dengan gue pernah disuruh ibu lat...  negative  negative\n",
       "..                                                 ...       ...       ...\n",
       "495  kata nya tidur yang baik itu minimal enam jam ...   neutral   neutral\n",
       "496                  indonesia itu ada di benua asia .   neutral   neutral\n",
       "497  salah satu kegemaran anak remaja indonesia sek...   neutral   neutral\n",
       "498  melihat warna hijau bisa bikin mata jadi lebih...  positive  positive\n",
       "499  bondan winarno yang suka bilang maknyus sekara...   neutral  positive\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66c91be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: bagus banget fotonya itu | Label : positive (99.888%)\n"
     ]
    }
   ],
   "source": [
    "text = 'bagus banget fotonya itu'\n",
    "subwords = tokenizer.encode(text)\n",
    "subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
    "\n",
    "logits = model(subwords)[0]\n",
    "label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()\n",
    "\n",
    "print(f'Text: {text} | Label : {i2w[label]} ({F.softmax(logits, dim=-1).squeeze()[label] * 100:.3f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a5e5cf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: pagi tadi pergi ke BLI | Label : neutral (99.787%)\n"
     ]
    }
   ],
   "source": [
    "text = 'pagi tadi pergi ke BLI'\n",
    "subwords = tokenizer.encode(text)\n",
    "subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
    "\n",
    "logits = model(subwords)[0]\n",
    "label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()\n",
    "\n",
    "print(f'Text: {text} | Label : {i2w[label]} ({F.softmax(logits, dim=-1).squeeze()[label] * 100:.3f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9ba33b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Dasar anak sialan!! Kurang ajar!! | Label : negative (99.885%)\n"
     ]
    }
   ],
   "source": [
    "text = 'Dasar anak sialan!! Kurang ajar!!'\n",
    "subwords = tokenizer.encode(text)\n",
    "subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
    "\n",
    "logits = model(subwords)[0]\n",
    "label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()\n",
    "\n",
    "print(f'Text: {text} | Label : {i2w[label]} ({F.softmax(logits, dim=-1).squeeze()[label] * 100:.3f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0aea07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "4fecf1a7-0de8-4cb0-afca-948168376b4f",
       "rows": [
        [
         "0",
         "packing rapi,aman...untuk tabletnya lumayan lah..sesuai harga...",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "1",
         "barang sesuai dg deskripsi, dapet harga murah, ori, sudah dicoba lancar jaya..tx lazada",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "2",
         "Barang sesuai pesanan.",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "3",
         "mantap, kualitas ok banget",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "4",
         "jangan pernah menyerah untuk beli produk Coocaa smart,,,, puuuuaaassssss",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "5",
         "TVnya oke biat harga segitu mantab",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "6",
         "Mantap benar sesuai dengan deskripsi singkat barang",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "7",
         "barangnya kecil banget..kirain seperti gambar gede",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "8",
         "Yg saya kira 64 gb ternyata 64 mb, ntah yg ngirm atau emg tulisan produk tsb sudah dignti entah lah. Yg terpnting menjadi pembelajaran buat ane & terima kasih lazada krna brg tdk sesuai dgn yg dihrapkan sdh kurirnya mminta tips pula krna emg kesalahan ane distu bgitu ditelpon oleh lazada lex saya lgi keluar.",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "9",
         "Barang oke sesuai deskripsi",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "10",
         "berfungsi baik,cma ngak full 16 giga,tpi14.5 giga tapi ngak apalah dengan harga segitu.",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "11",
         "barang sudah sya terima dalam keadaan baik",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "12",
         "paraah,,,,memory nya gk bisa nyimpen file,,,kecewa sayaaa,,",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "13",
         "Bagus ,kondisi barang sesuai dengan yg kita mau",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "14",
         "pengiriman cepat, kurir ramah (padahal b aja) barang mulus (iyalah 4.8jt)tapi tak semulus paha lucinta luna. gratis tas padahal kalo ditambah mouse mau kali customer namanya juga gretongan cuma sayang gdpt CD DRIVER padahal item itu penting bgt. tapi overall OK lah. yg terakhir tetap jaga AMANAH DARI CUSTOMER YA SEE YOU NEXT ORDER",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "15",
         "barang d terima dgn baik.. dan cukup bagus untuk led harga d bawah 2jt",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "16",
         "barang diterima dengan baik, sudah dicoba normal jaya",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "17",
         "parah,,,barang dak bisa pake, sy retur kembalikan",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "18",
         "Luar biasa. Recommended banget nih toko. Pengiriman cepat. Product Ori. Windows Ori. Tersegel Asus. Laptop belum pernah dipakai. Packing aman. Pokoknya sempurna. Terima Kasih 🙏",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "19",
         "android tv coocaa mendarat drngan aman di bali THX COOCAA N LAZADA,good job n great service",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "20",
         "barang original, packaging rapi dan aman, dan pengiriman cepat. garansi 10 tahun",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "21",
         "Ane puas banget gan.... Mantap Semula kirain ukuranya kecil... Malah pintu saya gk cukup buat masukin nih tv ke dalam rumah..terpaksa bongkar atap rumah deh agar bisa masuk..",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "22",
         "Ok",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "23",
         "thanks bosku barang telah kami terima dengan baik.semoga sukses selalu.dan makin laris bosku.mantap pokok nya",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "24",
         "Dear.Lazada Barangnya Udah Saya Terima.Packing Ok.Barang Ok.Terimakasih Lazada Dan Penjuanya.",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "25",
         "barang oke paking rapi menggunakan kayu baru sempat ulas, di pertahankan dan di tingkatkan 👍🙏",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "26",
         "bagus",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "27",
         "ini pengirimannya cepet banget... gokil",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "28",
         "pesaman telah sampai",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "29",
         "baguuuus",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "30",
         "lumayan lah, ngga mengecewakan 🤗",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "31",
         "product oke & mudah pengoperasiannya. tpi voucher free hooq 6 blnnya, cara dapatkannya bagaimana yaa?? tidak ada notif di email juga,,, mohon dikirimkan.",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "32",
         "2 x saya order TV xiaomi led 32\" dari Lazadda... alhamdulilah aman, lancar dan baik saja.... terima kasih Lazadda dan juga terima kasih tak tertinggal utk Ninja del van.... perpaduan yang luar biasa",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "33",
         "Excellent product, best price, saran saya design di perbaiki, semua akses seperti USB dan Output dapat di jangkau dari depan. Semoga awet deh.",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "34",
         "Barang oke, sampai dengan selamat, dan langsung berfungsi....... Thanks :)",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "35",
         "ini tv manteb sekali belum di transfer aja barang udah sampai kemaren, ayam saya suka dengan kardusnya sehingga betah untuk tidak keluar rumah.",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "36",
         "androidnya kok kitkat",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "37",
         "Packing kayu, kualitas bagus sekali, pokoknya sangat terbaik, pelayanan cepat, barang sampe juga cepat, pokoknya enggak nyesel, terimakasih coocaa",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "38",
         "produk cepat sampai n kualitas ok",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "39",
         "pengiriman cepat bgt... packing super aman.... pesan senin sore jam 4, selasa siang udah sampe.... barang sesuai yg diharapkan..... sudah dicoba dan berfungsi dgn baik, semoga aweet... :)",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "40",
         "warnanya bqgus.smua nya bagus.kurir nya jg baik.psn malam eh bsk nya siang siang sdh di antar.",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "41",
         "good job lazada cepat dan packing rapi",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "42",
         "Mantap",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "43",
         "pengiriman cepat, barang sampai di tempat bagus, tdk ada yg lecet dan berfungsi baik.",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "44",
         "Trimah ksih lazada barang y sudah smpai dan tidak cacat sedikit pun.kurir y pun ramah dlm pelayanan y.",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "45",
         "TV nya bagus, ga malu2in buat harga segitu, dan alhmadulillah bisa dapet sinyal digital, daerah kalideres dapet 27 ch. Pengiriman kilat pake jne, 1 hari langsung sampe. semoga awet dan terima kasih lazada",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "46",
         "buruk,,di komputer tidak terbaca.. nyesel beli produk ini.. dasar mau ambil untung doank. kualitas tidak jelas.",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "47",
         "memuaskan",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "48",
         "mulus",
         "isi ini ya ges (positive/neutral/negative)"
        ],
        [
         "49",
         "bagus mantap",
         "isi ini ya ges (positive/neutral/negative)"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 11000
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>packing rapi,aman...untuk tabletnya lumayan la...</td>\n",
       "      <td>isi ini ya ges (positive/neutral/negative)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>barang sesuai dg deskripsi, dapet harga murah,...</td>\n",
       "      <td>isi ini ya ges (positive/neutral/negative)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barang sesuai pesanan.</td>\n",
       "      <td>isi ini ya ges (positive/neutral/negative)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mantap, kualitas ok banget</td>\n",
       "      <td>isi ini ya ges (positive/neutral/negative)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jangan pernah menyerah untuk beli produk Cooca...</td>\n",
       "      <td>isi ini ya ges (positive/neutral/negative)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>no kommmeeennnn, very good!!!!</td>\n",
       "      <td>isi ini ya ges (positive/neutral/negative)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>macbook pertama dan barang dijamin asli. hanya...</td>\n",
       "      <td>isi ini ya ges (positive/neutral/negative)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>Untuk tv 40\" FHD harga cuma 1.999 sih murah se...</td>\n",
       "      <td>isi ini ya ges (positive/neutral/negative)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>mantap barangnya bagus bgt</td>\n",
       "      <td>isi ini ya ges (positive/neutral/negative)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>ko 2gb doang ya</td>\n",
       "      <td>isi ini ya ges (positive/neutral/negative)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                                   text  \\\n",
       "0      packing rapi,aman...untuk tabletnya lumayan la...   \n",
       "1      barang sesuai dg deskripsi, dapet harga murah,...   \n",
       "2                                 Barang sesuai pesanan.   \n",
       "3                             mantap, kualitas ok banget   \n",
       "4      jangan pernah menyerah untuk beli produk Cooca...   \n",
       "...                                                  ...   \n",
       "10995                     no kommmeeennnn, very good!!!!   \n",
       "10996  macbook pertama dan barang dijamin asli. hanya...   \n",
       "10997  Untuk tv 40\" FHD harga cuma 1.999 sih murah se...   \n",
       "10998                         mantap barangnya bagus bgt   \n",
       "10999                                    ko 2gb doang ya   \n",
       "\n",
       "0                                       sentiment  \n",
       "0      isi ini ya ges (positive/neutral/negative)  \n",
       "1      isi ini ya ges (positive/neutral/negative)  \n",
       "2      isi ini ya ges (positive/neutral/negative)  \n",
       "3      isi ini ya ges (positive/neutral/negative)  \n",
       "4      isi ini ya ges (positive/neutral/negative)  \n",
       "...                                           ...  \n",
       "10995  isi ini ya ges (positive/neutral/negative)  \n",
       "10996  isi ini ya ges (positive/neutral/negative)  \n",
       "10997  isi ini ya ges (positive/neutral/negative)  \n",
       "10998  isi ini ya ges (positive/neutral/negative)  \n",
       "10999  isi ini ya ges (positive/neutral/negative)  \n",
       "\n",
       "[11000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing with Lazada Indonesian Reviews\n",
    "lazada_reviews_path = '../data/lazada_reviews/lazada-reviews-without-sentiment.csv'\n",
    "\n",
    "# Remove unused columns and remove missing values\n",
    "lazada_df = pd.read_csv(lazada_reviews_path, header=None, low_memory=False)\n",
    "lazada_df.columns = lazada_df.iloc[0]\n",
    "lazada_df = lazada_df[1:]\n",
    "lazada_df = lazada_df.reset_index(drop=True)\n",
    "lazada_df = lazada_df[['reviewContent']].rename(columns={'reviewContent': 'text'})\n",
    "lazada_df = lazada_df.dropna()\n",
    "lazada_df['sentiment'] = 'isi ini ya ges (positive/neutral/negative)'\n",
    "\n",
    "sample_df = lazada_df.sample(n=11000, random_state=42).reset_index(drop=True)\n",
    "sample_df.to_csv('../data/lazada_reviews/train-lazada.csv')\n",
    "# sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aead48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "remaining_df = lazada_df[~lazada_df['text'].isin(sample_df['text'])]\n",
    "\n",
    "test_df = remaining_df.sample(n=500, random_state=99).reset_index(drop=True)\n",
    "test_df.to_csv('../data/lazada_reviews/test-lazada.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc00d3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_texts = set(sample_df['text']) | set(test_df['text'])\n",
    "\n",
    "new_remaining_df = lazada_df[~lazada_df['text'].isin(used_texts)]\n",
    "\n",
    "valid_df = remaining_df.sample(n=1260, random_state=123).reset_index(drop=True)\n",
    "valid_df.to_csv('../data/lazada_reviews/valid-lazada.csv')\n",
    "\n",
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cb4c900e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7464/107029 [05:29<1:13:21, 22.62it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[118]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Prediksi\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubwords_tensor\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     30\u001b[39m probs = F.softmax(logits, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m     31\u001b[39m label_id = torch.argmax(probs, dim=-\u001b[32m1\u001b[39m).item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/models/bert/modeling_bert.py:1483\u001b[39m, in \u001b[36mBertForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1475\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1476\u001b[39m \u001b[33;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[32m   1477\u001b[39m \u001b[33;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[32m   1478\u001b[39m \u001b[33;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[32m   1479\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m   1480\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1481\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1483\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1484\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1485\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1486\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1489\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1490\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1491\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1493\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1495\u001b[39m pooled_output = outputs[\u001b[32m1\u001b[39m]\n\u001b[32m   1497\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.dropout(pooled_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/models/bert/modeling_bert.py:996\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m    990\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m    991\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m    992\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m    993\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m    994\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m--> \u001b[39m\u001b[32m996\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1008\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1009\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/models/bert/modeling_bert.py:651\u001b[39m, in \u001b[36mBertEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    648\u001b[39m layer_head_mask = head_mask[i] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    649\u001b[39m past_key_value = past_key_values[i] \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    661\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/modeling_layers.py:83\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m         logger.warning(message)\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/models/bert/modeling_bert.py:595\u001b[39m, in \u001b[36mBertLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    592\u001b[39m     cross_attn_present_key_value = cross_attention_outputs[-\u001b[32m1\u001b[39m]\n\u001b[32m    593\u001b[39m     present_key_value = present_key_value + cross_attn_present_key_value\n\u001b[32m--> \u001b[39m\u001b[32m595\u001b[39m layer_output = \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    598\u001b[39m outputs = (layer_output,) + outputs\n\u001b[32m    600\u001b[39m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/pytorch_utils.py:250\u001b[39m, in \u001b[36mapply_chunking_to_forward\u001b[39m\u001b[34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[39m\n\u001b[32m    247\u001b[39m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[32m    248\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(output_chunks, dim=chunk_dim)\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/models/bert/modeling_bert.py:607\u001b[39m, in \u001b[36mBertLayer.feed_forward_chunk\u001b[39m\u001b[34m(self, attention_output)\u001b[39m\n\u001b[32m    606\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[32m--> \u001b[39m\u001b[32m607\u001b[39m     intermediate_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    608\u001b[39m     layer_output = \u001b[38;5;28mself\u001b[39m.output(intermediate_output, attention_output)\n\u001b[32m    609\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/models/bert/modeling_bert.py:508\u001b[39m, in \u001b[36mBertIntermediate.forward\u001b[39m\u001b[34m(self, hidden_states)\u001b[39m\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch.Tensor) -> torch.Tensor:\n\u001b[32m    507\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.dense(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mintermediate_act_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/activations.py:69\u001b[39m, in \u001b[36mGELUActivation.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# print(lazada_df.head())\n",
    "# print(lazada_df.columns)\n",
    "\n",
    "def encode_dataset_without_sentiment(df, tokenizer, no_special_token=False):\n",
    "    encoded = []\n",
    "    for text in df['text']:\n",
    "        subwords = tokenizer.encode(text, add_special_tokens=not no_special_token)\n",
    "        encoded.append((np.array(subwords), text))\n",
    "    return encoded\n",
    "\n",
    "lazada_encoded = encode_dataset_without_sentiment(lazada_df, tokenizer)\n",
    "\n",
    "lazada_loader = DataLoader(lazada_encoded, batch_size=32, shuffle=False, num_workers=8, collate_fn=lambda x: collate_fn(x, max_seq_len=512))\n",
    "\n",
    "model.eval()\n",
    "model.to('cpu')\n",
    "\n",
    "pred_labels = []\n",
    "pred_probs = []\n",
    "\n",
    "for text in tqdm(lazada_df['text']):\n",
    "    # Tokenisasi\n",
    "    subwords = tokenizer.encode(text, add_special_tokens=True)\n",
    "    subwords_tensor = torch.LongTensor(subwords).unsqueeze(0).to(model.device)\n",
    "\n",
    "    # Prediksi\n",
    "    with torch.no_grad():\n",
    "        logits = model(subwords_tensor)[0]\n",
    "\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    label_id = torch.argmax(probs, dim=-1).item()\n",
    "    confidence = probs.squeeze()[label_id].item()\n",
    "\n",
    "    pred_labels.append(label_id)\n",
    "    pred_probs.append(confidence)\n",
    "\n",
    "# 4. Simpan hasil prediksi\n",
    "lazada_df[\"label\"] = pred_labels\n",
    "lazada_df[\"label_name\"] = lazada_df[\"label\"].map(i2w)\n",
    "lazada_df[\"confidence\"] = pred_probs\n",
    "\n",
    "lazada_df.to_csv(\"data_dengan_label.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentika",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
