{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60c5b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from transformers import BertForSequenceClassification, BertConfig, BertTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef38d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# common functions\n",
    "###\n",
    "LABEL2INDEX = {'positive': 0, 'neutral': 1, 'negative': 2}\n",
    "INDEX2LABEL = {0: 'positive', 1: 'neutral', 2: 'negative'}\n",
    "NUM_LABELS = 3\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "def count_param(module, trainable=False):\n",
    "    if trainable:\n",
    "        return sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "    else:\n",
    "        return sum(p.numel() for p in module.parameters())\n",
    "    \n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def metrics_to_string(metric_dict):\n",
    "    string_list = []\n",
    "    for key, value in metric_dict.items():\n",
    "        string_list.append('{}:{:.2f}'.format(key, value))\n",
    "    return ' '.join(string_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1308fd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "set_seed(26092020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e65f947e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load Tokenizer and Config\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "config = BertConfig.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "config.num_labels = NUM_LABELS\n",
    "\n",
    "# Instantiate model\n",
    "model = BertForSequenceClassification.from_pretrained('indobenchmark/indobert-base-p1', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a359f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    df = pd.read_csv(path, sep='\\t', header=None)\n",
    "    df.columns = ['text', 'sentiment']\n",
    "    df['sentiment'] = df['sentiment'].apply(lambda lab: LABEL2INDEX[lab])\n",
    "    return df\n",
    "\n",
    "def encode_dataset(df, tokenizer, no_special_token=False):\n",
    "    encoded = []\n",
    "    for _, row in df.iterrows():\n",
    "        text = row['text']\n",
    "        sentiment = row['sentiment']\n",
    "        subwords = tokenizer.encode(text, add_special_tokens=not no_special_token)\n",
    "        encoded.append((np.array(subwords), np.array(sentiment), text))\n",
    "    return encoded\n",
    "\n",
    "def collate_fn(batch, max_seq_len=512):\n",
    "    batch_size = len(batch)\n",
    "    max_len = min(max(len(x[0]) for x in batch), max_seq_len)\n",
    "    \n",
    "    subword_batch = np.zeros((batch_size, max_len), dtype=np.int64)\n",
    "    mask_batch = np.zeros((batch_size, max_len), dtype=np.float32)\n",
    "    sentiment_batch = np.zeros((batch_size, 1), dtype=np.int64)\n",
    "    seq_list = []\n",
    "\n",
    "    for i, (subwords, sentiment, raw_seq) in enumerate(batch):\n",
    "        subwords = subwords[:max_len]\n",
    "        subword_batch[i, :len(subwords)] = subwords\n",
    "        mask_batch[i, :len(subwords)] = 1\n",
    "        sentiment_batch[i, 0] = sentiment\n",
    "        seq_list.append(raw_seq)\n",
    "\n",
    "    return (\n",
    "        torch.tensor(subword_batch),\n",
    "        torch.tensor(mask_batch),\n",
    "        torch.tensor(sentiment_batch),\n",
    "        seq_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e15e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = '../data/train_preprocess.tsv'\n",
    "valid_dataset_path = '../data/valid_preprocess.tsv'\n",
    "test_dataset_path = '../data/test_preprocess.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c60d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_dataset(train_dataset_path)\n",
    "valid_df = load_dataset(valid_dataset_path)\n",
    "test_df  = load_dataset(test_dataset_path)\n",
    "\n",
    "train_encoded = encode_dataset(train_df, tokenizer)\n",
    "valid_encoded = encode_dataset(valid_df, tokenizer)\n",
    "test_encoded  = encode_dataset(test_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b87f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_encoded, batch_size=32, shuffle=True, num_workers=8,\n",
    "    collate_fn=lambda x: collate_fn(x, max_seq_len=512)\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_encoded, batch_size=32, shuffle=False, num_workers=8,\n",
    "    collate_fn=lambda x: collate_fn(x, max_seq_len=512)\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_encoded, batch_size=32, shuffle=False, num_workers=8,\n",
    "    collate_fn=lambda x: collate_fn(x, max_seq_len=512)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9b1cad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'positive': 0, 'neutral': 1, 'negative': 2}\n",
      "{0: 'positive', 1: 'neutral', 2: 'negative'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "afb8434d-3b97-4e05-8c48-64e7c92234fc",
       "rows": [
        [
         "0",
         "warung ini dimiliki oleh pengusaha pabrik tahu yang sudah puluhan tahun terkenal membuat tahu putih di bandung . tahu berkualitas , dipadu keahlian memasak , dipadu kretivitas , jadilah warung yang menyajikan menu utama berbahan tahu , ditambah menu umum lain seperti ayam . semuanya selera indonesia . harga cukup terjangkau . jangan lewatkan tahu bletoka nya , tidak kalah dengan yang asli dari tegal !",
         "0"
        ],
        [
         "1",
         "mohon ulama lurus dan k212 mmbri hujjah partai apa yang harus diwlh agar suara islam tidak pecah-pecah",
         "1"
        ],
        [
         "2",
         "lokasi strategis di jalan sumatera bandung . tempat nya nyaman terutama sofa di lantai 2 . paella nya enak , sangat pas dimakan dengan minum bir dingin . appetiser nya juga enak-enak .",
         "0"
        ],
        [
         "3",
         "betapa bahagia nya diri ini saat unboxing paket dan barang nya bagus ! menetapkan beli lagi !",
         "0"
        ],
        [
         "4",
         "duh . jadi mahasiswa jangan sombong dong . kasih kartu kuning segala . belajar dulu yang baik , tidak usahlah ikut-ikut politik . nanti sudah selesai kuliah nya mau ikut politik juga tidak telat . dasar mahasiswa .",
         "2"
        ],
        [
         "5",
         "makanan beragam , harga makanan di food stall akan ditambahkan 10 % lagi di kasir , suasana ramai dan perlu perhatian untuk mendapatkan parkir dan tempat duduk .",
         "0"
        ],
        [
         "6",
         "pakai kartu kredit bca tidak untung malah rugi besar",
         "2"
        ],
        [
         "7",
         "tempat unik , bagus buat foto , makanan enak , pegawai ramah , bersih dan luas , wifi kencang . harga standar dan sesuai dengan tempat nya . ada menu masakan makanan barat dan indonesia . menu favorit lychee mojito dan spagheti",
         "0"
        ],
        [
         "8",
         "saya bersama keluarga baru saja menikmati pengalaman kuliner yang menyenangkan di rm sari sunda di jalan . setiabudhi , bandung . tapi , karena tidak ada hubungan untuk rm sari sunda di jalan . setiabudhi , maka saya tuliskan di sini . jadi , maaf jika rekan-rekan pembaca ada yang bingung . beberapa hal yang saya suka dari restoran ini adalah bahwa pelayanan restoran ini terbilang cepat .",
         "0"
        ],
        [
         "9",
         "bersyukur",
         "0"
        ],
        [
         "10",
         "simcard indosat inaktiv gara-gara lupa isi pulsa dan kabar nya aktif jika pinda ke pasca bayar , ribet banget",
         "2"
        ],
        [
         "11",
         "sifat iri sering muncul pada orang orang yang tidak punya tujuan hidup",
         "2"
        ],
        [
         "12",
         "sekadar menceritakan pengalaman saya pesan steak grilled beef 200 tidak disajikanlah steak 200 tidak tersebut dalam 2 potongan 100 tidak - 100 tidak rasanya tidak buruk , namun kualitas daging nya yang membuat saya enggan memesan menu beef lagi khusus nya sirloin karena lemak nya terlalu banyak untuk ukuran steak namun , masih ada menu-menu lain yang sangat menempel di lidah saya sarankan untuk membeli menu berlabel cheese atau . lanjutan",
         "0"
        ],
        [
         "13",
         "pengalaman bersama indosat hari ini , semoga tidak terjadi pada pelanggan lain . sempat sampai marah-marah dengan pelayanan pelanggan indosat",
         "2"
        ],
        [
         "14",
         "anak sekarang sulit untuk dinasehati",
         "2"
        ],
        [
         "15",
         "hanya mengatasi masalah kayak gini saja anies sandi tidak becus . ke mana saja pasukan kebersihan yang begitu banyak jumlah nya ?",
         "2"
        ],
        [
         "16",
         "setiap bumn dibentuk dengan uu bukan dibentuk dengan uu .",
         "1"
        ],
        [
         "17",
         "sehabis puas bermain di trans studio bandung , saya bersama teman sepakat untuk makan ayam kakek di sini . ayam nya selalu enak dan gurih !",
         "0"
        ],
        [
         "18",
         "rasa bakso cuanki dan batagor cukup . selalu ramai pengunjung . buka sekitar jam 10 pagi . dari jalan riau menuju jalan a yani ada sisi kiri jalan sekitar jalan anggrek . harga per porsi sekitar rp 14 000 . datanglah lebih awal karena selalu ramai pengunjung",
         "0"
        ],
        [
         "19",
         "sgwr 2018 beri dampak positif terhadap hobi anak-anak",
         "0"
        ],
        [
         "20",
         "berada di lembang , pemandangan indah , udara sejuk , penataan resto yang bagus , dilengkapi dengan makanan yang sangat nikmat . pilihan menu beragam dan minuman yang lengkap . lingkungan yang cocok untuk makan berdua dengan pasangan , membawa keluarga ataupun bersama dengan teman . lapangan parkir luas . restoran yang berkonsep terbuka ini membuat udara lembang sangat terasa sejuk nya .",
         "0"
        ],
        [
         "21",
         "berbuka puasa di sini pada minggu lepas , pak supir yang mencadangkan tempat makan ini . makanan nya di sini sedap dan harga berpatutan . tempat nya luas dan cantik . rekomendasi too others to dine in here to rasa authentic sunda makanan indonesia .",
         "0"
        ],
        [
         "22",
         "hahaha suka banget nonton kartun indonesia keluarga pak tomat",
         "0"
        ],
        [
         "23",
         "bagi teman-teman yang sedang berkunjung ke bandung bisa mampir ke kopi anjis untuk makan makanan yang tidak terlalu berat . ada cilok rakyat ditemankan dengan teh sereh dan lekker .",
         "0"
        ],
        [
         "24",
         "di restoran ini , saya dan keluarga makan malam yang terakhir di bandung . kami berjumlah 8 orang dan bila nya hanya sekitar 400 an , benar-benar murah meriah , sampai makan double-double lagi . makanan nya juga enak , suasana kafe menarik , pelayanan sangat bagus . saya masih teringat petunjuk toilet yang ada di restoran ini men to the pergi , karena momen are selalu ribut hahahaha . setimpal .",
         "0"
        ],
        [
         "25",
         "alhamdulillah hari ini tidak ke jalan bugel agak kesal juga kalau tiap hari lewat sana melulu . sempit , dua arah , macet sudah jadi makanan sehari-hari",
         "2"
        ],
        [
         "26",
         "respon agak lama , sama sayang nya rem nya bukan asli , masih rom distrobitor",
         "2"
        ],
        [
         "27",
         "lokasi dengan pemandangan alam yang masih natural dan indah . suasana juga sejuk dan tenang . hanya saja banyak nyamuk dan harga makanan relatif mahal .",
         "0"
        ],
        [
         "28",
         "pdip sebut ridwan kamil menang karena berbaju merah",
         "1"
        ],
        [
         "29",
         "malu - maluin nih oknum yang tidak bertanggung jawab .",
         "2"
        ],
        [
         "30",
         "makan siang di sini asyik juga . nuansa bali walaupun music nya musik sunda kadang musik khas bali bergantian . tempat nya enak dan adem tapi sayang sekali pesan kopi lama banget datang nya , diminta berkali kali , iya pak iya pak hampir 1 jam dan ketika kopi datang pun bukan kopi panas tapi kopi ade , ini kah ciri khas kopi di sini . kalau khas nya kopi dingin tidak enak .",
         "2"
        ],
        [
         "31",
         "tempat steak di bandung sejak lama dari zaman setiabudi sampai sekarang buka cabang di riau . tempat di riau ini lebih besar , parkiran juga tidak sulit seperti di setiabudi . lokasi di tempat kuliner jalan riau . porsi dan harga nya pas untuk ukuran steak . untuk zoom non smoking nya nyaman .",
         "0"
        ],
        [
         "32",
         "08:30 : kedatangan presiden ri dan rombongan di gate 2 , terminal 3 disambut oleh menteri perhubungan , menteri bumn , gubernur banten , dirjen perkeretaapian kemhub , dirut ap2 , dirut pt kami , dan dirut railink",
         "1"
        ],
        [
         "33",
         "makanan tradisional yang selalu rasanya stabil iga garang asam nya dan java steak nya jangan lupa ya dicoba hidangan penutup semua kue enak lemper soes fla gulung . enak sekali tidak ada yang tidak enak kalau makanan di sini .",
         "0"
        ],
        [
         "34",
         "sampai saat ini saya rasa batagor ini masih yang terenak di kota bandung dibandingkan dengan batagor lainnya yang saya pernah coba . bumbu kacang nya pas rasanya di lidah , dan batagor nya juga tidak amis bau nya . silakan mencoba untuk yang belum pernah coba .",
         "0"
        ],
        [
         "35",
         "aroma khas yang ada jika makan di atas daun pisang , ya walau ramai tempat ini selalu jadi favourit saya jika ke bandung .",
         "0"
        ],
        [
         "36",
         "akhir tahun lalu saya dan keluarga berjalan ke daerah lembang dan tidak sengaja mampir makan di resto ini . suasana nya nyaman , pelayanan juga ramah dan berlebihan ala kami puas . makanan yang di sajikan standar seperti makanan di restoran pada umum nya , tetapi yang membuat berbeda adalah sambal stroberi yang yummy dan bikin ketagihan . di sana selain bisa makan kita juga bisa sambil memetik . lanjutan",
         "0"
        ],
        [
         "37",
         "risma menjatuhkan pilihan nya pada gus ipul - puti di pilgub jatim 2018 ini .",
         "1"
        ],
        [
         "38",
         "pengalaman yang cukup seru , makan tanpa alas piring , tapi hanya dengan alas daun , makin nikmat . makanan sunda yang sangat bervariatif dan cukup enak . tips nya : jangan terbawa emosi dan kalap memesan dan memilih semua makanan yang disediakan biasanya kalap kalau sudah melihat makanan macam-macam begitu . pilih seperlunya .",
         "0"
        ],
        [
         "39",
         "makanan nya enak , suasana nyaman . harga bisa dibilang sama dengan tempat lain . restoran ini ada 4 konsep tapi yang paling terkenal menu jepang nya yang enak loh",
         "0"
        ],
        [
         "40",
         "kampung daun adalah tempat makan yang menyatukan konsep alam dan budaya dari daerah setempat . walaupun di dalam kompleks perumahan akan tetapi tempat tersebut cukup luas mempunyai mungkin sekitar 20 lebih saung / tempat makan dari yang kapasitas sedang hingga besar . kualitas makanan enak dan dengan ada nya suara riak air dari air terjun kecil di sana membuat suasana sangat nyaman untuk makan .",
         "0"
        ],
        [
         "41",
         "waktu itu ke sini pesan nasi goreng dan kentang goreng , nasi goreng nya semua suka . kentang goreng nya enak banget , dan presentasi nya bagus . keluarga bilang kopi nya enak . hal yang sangat baik di sini adalah tempat nya luas dan yang di luar bisa lihat pemandangan dusun bambu , tapi pelayanan nya tidak cepat sehingga saya harus bertanya beberapa kali tentang pesanan saya . harga nya cukup mahal , namun karena makanan nya enak semua jadi terbayarkan . tidak perlu pikir dua kali jika mau ke tempat ini lagi .",
         "0"
        ],
        [
         "42",
         "banyak sekali tempat makan sunda yang bertebaran di kota bandung , tetapi tidak tahu kenapa saya sangat jatuh hati dengan sebuah warung makan ini . ibu imas yang berada di dekat alun-alun kota bandung menyuguhkan rumah makan sunda dengan karakter warung nasi zaman dahulu yang di mana kita bisa mengambil semua hidangan di depan kita tanpa harus melalui proses order yang biasa kita jumpai di warung makan .",
         "0"
        ],
        [
         "43",
         "hai tolong bantu saya tidak bisa input tidak resi jne dan kenomor resi sudah dipakai .",
         "1"
        ],
        [
         "44",
         "foods : menu baru cheeseburger nya oke banget dan chicken wings pizza hut memang selalu juara . dirilis : mixing green tea yakult , perfect ! satu-satunya kekurangan pizza hut adalah pinggiran nya ,",
         "0"
        ],
        [
         "45",
         "dusun bambu ini tergolong baru di bandung . tempat nya yang dekat banget sama almamater saya . membuat saya gampang cari ini tempat . pemandangan nya bagus . banyak tempat makan yang enak-enak . beli nya nanti pakai voucher .",
         "0"
        ],
        [
         "46",
         "tidak memuaskan",
         "2"
        ],
        [
         "47",
         "suruh ngaca pemain nya ! dasar oneng ! ngomong saja masih ala betawi lu ! kampungan !",
         "2"
        ],
        [
         "48",
         "kafe ini menyajikan sensasi makan dalam gelap . cukup unik sih , tetapi lebih dari sekali , rasanya orang jarang datang lagi . hanya menarik untuk sekadar mencoba .",
         "2"
        ],
        [
         "49",
         "sesuai dengan nama nya mi awie , kedai makan ini menyediakan menu mi dengan olahan daging babi . selain mi masih ada pilihan lainnya seperti nasi goreng babi , capjay goreng , bakso , pangsit dan lainnya . kami mencoba menu mi babi casau special , rasanya . enak banget !",
         "0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 11000
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>tidak kecewa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>enak rasa masakan nya apalagi kepiting yang me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>hormati partai-partai yang telah berkoalisi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>pagi pagi di tol pasteur sudah macet parah , b...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>meskipun sering belanja ke yogya di riau junct...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment\n",
       "0      warung ini dimiliki oleh pengusaha pabrik tahu...          0\n",
       "1      mohon ulama lurus dan k212 mmbri hujjah partai...          1\n",
       "2      lokasi strategis di jalan sumatera bandung . t...          0\n",
       "3      betapa bahagia nya diri ini saat unboxing pake...          0\n",
       "4      duh . jadi mahasiswa jangan sombong dong . kas...          2\n",
       "...                                                  ...        ...\n",
       "10995                                       tidak kecewa          0\n",
       "10996  enak rasa masakan nya apalagi kepiting yang me...          0\n",
       "10997        hormati partai-partai yang telah berkoalisi          1\n",
       "10998  pagi pagi di tol pasteur sudah macet parah , b...          2\n",
       "10999  meskipun sering belanja ke yogya di riau junct...          0\n",
       "\n",
       "[11000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i, i2w = LABEL2INDEX, INDEX2LABEL\n",
    "print(w2i)\n",
    "print(i2w)\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b4bc087",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=5e-6)\n",
    "model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5648aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_sequence_classification(model, batch_data, i2w, is_test=False, device='cpu'):\n",
    "    \"\"\"\n",
    "    Forward function for sequence classification.\n",
    "    \n",
    "    Parameters:\n",
    "        model      : torch.nn.Module\n",
    "        batch_data : tuple of (input_ids, attention_mask, [token_type_ids], labels)\n",
    "        i2w        : dict, index to label mapping\n",
    "        is_test    : bool, whether test mode (optional)\n",
    "        device     : str or torch.device\n",
    "    \n",
    "    Returns:\n",
    "        loss       : torch.Tensor\n",
    "        list_hyp   : list of predicted labels\n",
    "        list_label : list of ground truth labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # Move data to tensors\n",
    "    if len(batch_data) == 3:\n",
    "        input_ids, attention_mask, labels = batch_data\n",
    "        token_type_ids = None\n",
    "    else:\n",
    "        input_ids, attention_mask, token_type_ids, labels = batch_data\n",
    "    \n",
    "    input_ids = torch.as_tensor(input_ids).to(device)\n",
    "    attention_mask = torch.as_tensor(attention_mask).to(device)\n",
    "    labels = torch.as_tensor(labels).to(device)\n",
    "    \n",
    "    if token_type_ids is not None:\n",
    "        token_type_ids = torch.tensor(token_type_ids).to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(\n",
    "        input_ids, \n",
    "        attention_mask=attention_mask, \n",
    "        token_type_ids=token_type_ids, \n",
    "        labels=labels\n",
    "    )\n",
    "    loss, logits = outputs[:2]\n",
    "\n",
    "    # Get predictions\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    \n",
    "    list_hyp = [i2w[p.item()] for p in preds]\n",
    "    list_label = [i2w[l.item()] for l in labels]\n",
    "\n",
    "    return loss, list_hyp, list_label\n",
    "\n",
    "def document_sentiment_metrics_fn(list_hyp, list_label):\n",
    "    metrics = {}\n",
    "    metrics[\"ACC\"] = accuracy_score(list_label, list_hyp)\n",
    "    metrics[\"F1\"] = f1_score(list_label, list_hyp, average='macro')\n",
    "    metrics[\"REC\"] = recall_score(list_label, list_hyp, average='macro')\n",
    "    metrics[\"PRE\"] = precision_score(list_label, list_hyp, average='macro')\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab072de",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 6\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    torch.set_grad_enabled(True)\n",
    "\n",
    "    total_train_loss = 0\n",
    "    list_hyp, list_label = [], []\n",
    "\n",
    "    train_pbar = tqdm(train_loader, leave=True, total=len(train_loader))\n",
    "    for i, batch_data in enumerate(train_pbar):\n",
    "        # Forward model\n",
    "        loss, batch_hyp, batch_label = forward_sequence_classification(\n",
    "            model, batch_data[:-1], i2w=i2w, device='cpu'\n",
    "        )\n",
    "\n",
    "        # Update model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tr_loss = loss.item()\n",
    "        total_train_loss += tr_loss\n",
    "\n",
    "        # Track predictions\n",
    "        list_hyp += batch_hyp\n",
    "        list_label += batch_label\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        train_pbar.set_description(\n",
    "            f\"(Epoch {epoch+1}) TRAIN LOSS:{total_train_loss/(i+1):.4f} LR:{current_lr:.8f}\"\n",
    "        )\n",
    "\n",
    "    # Train metrics\n",
    "    metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
    "    print(f\"(Epoch {epoch+1}) TRAIN LOSS:{total_train_loss/(i+1):.4f} {metrics_to_string(metrics)} \"\n",
    "        f\"LR:{current_lr:.8f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    total_loss = 0\n",
    "    list_hyp, list_label = [], []\n",
    "\n",
    "    pbar = tqdm(valid_loader, leave=True, total=len(valid_loader))\n",
    "    for i, batch_data in enumerate(pbar):\n",
    "        loss, batch_hyp, batch_label = forward_sequence_classification(\n",
    "            model, batch_data[:-1], i2w=i2w, device='cpu'\n",
    "        )\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        list_hyp += batch_hyp\n",
    "        list_label += batch_label\n",
    "\n",
    "        metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
    "        pbar.set_description(\n",
    "            f\"VALID LOSS:{total_loss/(i+1):.4f} {metrics_to_string(metrics)}\"\n",
    "        )\n",
    "\n",
    "    metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
    "    print(f\"(Epoch {epoch+1}) VALID LOSS:{total_loss/(i+1):.4f} {metrics_to_string(metrics)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1990f5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:27<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Metrics | ACC:0.91 F1:0.89 REC:0.87 PRE:0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test\n",
    "model.load_state_dict(torch.load(\"../backend/model/indobert_sentiment.pt\", map_location='cpu'))\n",
    "model.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "total_loss, total_correct, total_labels = 0, 0, 0\n",
    "list_hyp, list_label = [], []\n",
    "\n",
    "pbar = tqdm(test_loader, leave=True, total=len(test_loader))\n",
    "for i, batch_data in enumerate(pbar):\n",
    "    _, batch_hyp, batch_label = forward_sequence_classification(model, batch_data[:-1], i2w=i2w, device='cpu')\n",
    "    list_hyp += batch_hyp\n",
    "    list_label += batch_label\n",
    "metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
    "print(\"TEST Metrics | {}\".format(metrics_to_string(metrics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66c91be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: bagus banget fotonya itu | Label : positive (99.888%)\n"
     ]
    }
   ],
   "source": [
    "text = 'bagus banget fotonya itu'\n",
    "subwords = tokenizer.encode(text)\n",
    "subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
    "\n",
    "logits = model(subwords)[0]\n",
    "label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()\n",
    "\n",
    "print(f'Text: {text} | Label : {i2w[label]} ({F.softmax(logits, dim=-1).squeeze()[label] * 100:.3f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5e5cf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: pagi tadi pergi ke BLI | Label : neutral (99.787%)\n"
     ]
    }
   ],
   "source": [
    "text = 'pagi tadi pergi ke BLI'\n",
    "subwords = tokenizer.encode(text)\n",
    "subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
    "\n",
    "logits = model(subwords)[0]\n",
    "label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()\n",
    "\n",
    "print(f'Text: {text} | Label : {i2w[label]} ({F.softmax(logits, dim=-1).squeeze()[label] * 100:.3f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ba33b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Dasar anak sialan!! Kurang ajar!! | Label : negative (99.885%)\n"
     ]
    }
   ],
   "source": [
    "text = 'Dasar anak sialan!! Kurang ajar!!'\n",
    "subwords = tokenizer.encode(text)\n",
    "subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
    "\n",
    "logits = model(subwords)[0]\n",
    "label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()\n",
    "\n",
    "print(f'Text: {text} | Label : {i2w[label]} ({F.softmax(logits, dim=-1).squeeze()[label] * 100:.3f}%)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentika",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
